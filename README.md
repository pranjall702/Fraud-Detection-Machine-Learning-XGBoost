# Fraud-Detection-Machine-Learning-XGBoost
End-to-end Fraud Detection Model using XGBoost, SMOTE, and Imbalanced Data Handling. Safe pipeline with ROC, PR curve, and feature importance

# Fraud Detection Using Machine Learning

## 🔍 Problem Statement:
Build a fraud detection model to identify suspicious transactions in financial data.

## 🚀 What I Did:
- Cleaned and preprocessed the data
- Handled imbalanced data using **SMOTE**
- Trained an **XGBoost Classifier**
- Evaluated using **ROC AUC**, **Precision-Recall Curve**, **Confusion Matrix**
- Identified **Important Fraud Indicators (Feature Importance)**

## 📊 Visualizations:
- ROC Curve → How well the model catches fraud
- Precision-Recall Curve → How careful the model is in detecting fraud
- Feature Importance → What clues the model looks at

## ⚙️ Technologies Used:
- Python  
- XGBoost  
- imbalanced-learn  
- scikit-learn  
- matplotlib, seaborn  

## 📝 Notes:
This pipeline is built to handle **real-world fraud detection issues**, including:
- Highly imbalanced data  
- Safe checks when there is no fraud in training data  
- End-to-end workflow from data cleaning to evaluation
